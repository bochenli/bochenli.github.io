<!DOCTYPE html>
<html>

<head>
	<link rel="stylesheet" type="text/css" href="style.css" />
	<title>Bochen Li</title>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="author" content="Bochen Li">
</head>

<body>
<div id="container"; style="height=2000px; width:1500px; float:center;">
	<div id="menu"; style="background-color:#A3E4D7 ;height:2000px;width:200px;float:left;">
		<h2><a href="http://www.rochester.edu/"><img src="resource/rochester-logo.png"></a></h2>
        <a href="index.html", style="text-decoration:none"><h2 class="menu">Home</h2></a>
        <a href="resource/CV_BochenLi.pdf", style="text-decoration:none" target="_blank"><h2 class="menu">CV</h2></a>
        <a href="project.html", style="text-decoration:none"><h2 class="menu">Projects</h2></a>
        <a href="publication.html", style="text-decoration:none"><h2 class="menu">Publications</h2></a>
        <a href="experience.html", style="text-decoration:none"><h2 class="menu">Experiences</h2></a>
        <a href="http://www.ece.rochester.edu/projects/air/index.html", style="text-decoration:none"><h2 class="menu">AIR Lab</h2></a>

<!--        <a href="resource/Research.html", style="text-decoration:none"><h2 class="menu">Research</h2></a>
        <a href="resource/Publications.html", style="text-decoration:none"><h2 class="menu">Publications</h2></a>
        <a href="resource/Resources.html", style="text-decoration:none"><h2 class="menu">Resources</h2></a>
        <a href="http://www.ece.rochester.edu/projects/air/index.html", style="text-decoration:none"><h2 class="menu">AIR Lab</h2></a>-->
    </div>
    
    <div id="content"; style="background-color:#FFFFFF;height:900px;width:900px;float:left;">
		
        
        <div id="container"; class="padded"; style="width:900px; float:center;">

            <h1>Projects</h1>
            

            <div style="width:180px;float:left;">
            <img src="image/icon_av_singing.png" width="150">
            </div>
            <h3 class="top1"><a href="http://project/av_singing_separation.html">Audiovisual Singing Voice Separation</a></h3>
            <p> 
                Separating a song into vocal and accompaniment components is an active research topic, and recent years witnessed an increased performance from supervised training using deep learning techniques. We propose to apply the visual information corresponding to the singersâ€™ vocal activities to further improve the quality of the separated vocal signals.
            </p>
            
            <br><br>
            <hr>

            <div style="width:180px;float:left;">
            <img src="image/icon_ursing.png" width="150">
            </div>
            <h3 class="top1"><a href="project/URSing.html">URSing Dataset</a></h3>
            <p> 
                We introduce a dataset for facilitating audio-visual analysis of singing performances. The dataset comprises a number of singing performances as audio and video recordings. Each song contains the isolated track of solo singing voice and the mixure with accompaniment track. We anticipate that the dataset will be useful for multi-modal analysis of singing performances, such as audiovisual singing voice separation, and serve as ground-truth for evaluations.
            </p>
            <br>
            
            <hr>




            <div style="width:180px;float:left;">
            <img src="image/icon_query.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www2.ece.rochester.edu/~bli23/projects/query.html">Query by Video: Cross-modal Music Retrieval</a></h3>
            <p> We present the results where given an unconstrained video we recommend music from a large catalog based on the deep emotion representations learned from the two modalities.</p>
            
            <br><br><br>
            <hr>


            
            <div style="width:180px;float:left;">
            <img src="image/icon_skeleton.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www.ece.rochester.edu/projects/air/projects/skeletonpianist.html">Skeleton Plays Piano: Generating Pianist Movement from MIDI Data</a></h3>
            <p> We train a model to take the input of MIDI data, and output the visual performance as expressive body movements for pianist. It can be used for demonstration purpose for music learners, or immersive music enjoyment system, or human-computer interactions in automatic accompaniment systems. We show all the demo videos of the generated visual performance.</p>
            
            <br>
            <hr>


            <div style="width:180px;float:left;">
            <img src="image/icon_av_music.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www.ece.rochester.edu/projects/air/projects/av_music.html">Audio-visual Analysis of Music Performance</a></h3>
            <p> We propose to leverage visual information captured from music performance videos to advance several music information retrieval (MIR) tasks, such as source association, multi-pitch analysis, and vibrato analysis.  </p>

            <br><br><br>
            <hr>

            <div style="width:180px;float:left;">
            <img src="image/icon_URMP.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www.ece.rochester.edu/projects/air/projects/URMP.html">URMP Dataset</a></h3>
            <p> We create an audio-visual, multi-track, and multi-instrument music performance dataset that comprises a number of chamber music assembled from coordinated but separately recorded performances of individual tracks. With ground-truth pitch/note annotations and clean individual audio tracks available, this can be used for multi-modal analysis of music performance. </p>
            
            <br>
            <hr>

            <div style="width:180px;float:left;">
            <img src="image/icon_scoreFollowing.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www2.ece.rochester.edu/projects/air/projects/scorefollowing.html">Score Following For Expressive Piano Performance</a></h3>
            <p> We address the "sustained effect" in piano music performance, caused by the usage of sustained pedal or legato articulations. Due to this effect, the mixture of energy between the sustained and following notes (non-notated in the score) always results in delay erros in score following systems. We propose to modify the audio feature representations to reduce the sustained effect and enhance the robustness of score following systems. </p>
            
            <br>
            <hr>



            <div style="width:180px;float:left;">
            <img src="image/icon_lyricsDisplay.png" width="150">
            </div>
            <h3 class="top1"><a href="http://www2.ece.rochester.edu/projects/air/projects/lyricsdisplay.html">Automatic Lyrics Display For A Live Chorus Performance</a></h3>
            <p> Live musical performances (e.g., choruses, concerts, and operas) often require the display of lyrics for the convenience of the audience. We propose a computational system to automate this real-time lyrics display process using signal processing techniques </p>
            
            <br><br>
            <hr>



        </div> 



<!--         <div id="separator"; style="background-color:#FFFFFF;width:900px;float:left;">
        	<img src="resource/space.png" width="450" height="2">
        </div> -->
      
     
    </div>    
</div>



</body>
</html>
